{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabeedea",
   "metadata": {},
   "source": [
    "# Understanding NuScenes dataset and creating functions\n",
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae38a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43736a",
   "metadata": {},
   "source": [
    "Load nuscnenes mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c025a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.455 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', dataroot='data/sets/nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d565",
   "metadata": {},
   "source": [
    "Look at what each scene contains based on description etc. Below, the city/area is significant to us as well as the roadway type/description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e5b2ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0061, Parked truck, construction, intersectio... [18-07-24 03:28:47]   19s, singapore-onenorth, #anns:4622\n",
      "scene-0103, Many peds right, wait for turning car, ... [18-08-01 19:26:43]   19s, boston-seaport, #anns:2046\n",
      "scene-0655, Parking lot, parked cars, jaywalker, be... [18-08-27 15:51:32]   20s, boston-seaport, #anns:2332\n",
      "scene-0553, Wait at intersection, bicycle, large tr... [18-08-28 20:48:16]   20s, boston-seaport, #anns:1950\n",
      "scene-0757, Arrive at busy intersection, bus, wait ... [18-08-30 19:25:08]   20s, boston-seaport, #anns:592\n",
      "scene-0796, Scooter, peds on sidewalk, bus, cars, t... [18-10-02 02:52:24]   20s, singapore-queensto, #anns:708\n",
      "scene-0916, Parking lot, bicycle rack, parked bicyc... [18-10-08 07:37:13]   20s, singapore-queensto, #anns:2387\n",
      "scene-1077, Night, big street, bus stop, high speed... [18-11-21 11:39:27]   20s, singapore-hollandv, #anns:890\n",
      "scene-1094, Night, after rain, many peds, PMD, ped ... [18-11-21 11:47:27]   19s, singapore-hollandv, #anns:1762\n",
      "scene-1100, Night, peds in sidewalk, peds cross cro... [18-11-21 11:49:47]   19s, singapore-hollandv, #anns:935\n"
     ]
    }
   ],
   "source": [
    "nusc.list_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e188e",
   "metadata": {},
   "source": [
    "Below, we can see how many samples we have of each type of scenario/scene. This gives us a greater insight into what the dataset contains. The cell underneath then allows us to see the different information we can find within the dataset and allows us to explore NuScenes a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd608323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parked truck, construction, intersection, turn left, following a van : 39 samples\n",
      "Many peds right, wait for turning car, long bike rack left, cyclist : 40 samples\n",
      "Wait at intersection, bicycle, large truck, peds crossing crosswalk, ped with stroller : 41 samples\n",
      "Parking lot, parked cars, jaywalker, bendy bus, gardening vehicles : 41 samples\n",
      "Arrive at busy intersection, bus, wait at intersection, bicycle, peds : 41 samples\n",
      "Scooter, peds on sidewalk, bus, cars, truck, fake construction worker, bicycle, cross intersection, car overtaking us : 40 samples\n",
      "Parking lot, bicycle rack, parked bicycles, bus, many peds, parked scooters, parked motorcycle : 41 samples\n",
      "Night, big street, bus stop, high speed, construction vehicle : 41 samples\n",
      "Night, after rain, many peds, PMD, ped with bag, jaywalker, truck, scooter : 40 samples\n",
      "Night, peds in sidewalk, peds cross crosswalk, scooter, PMD, difficult lighting : 40 samples\n"
     ]
    }
   ],
   "source": [
    "# Sample type and number of that sample\n",
    "for i in range(len(nusc.scene)):\n",
    "    my_scene = nusc.scene[i]\n",
    "    description = my_scene['description']\n",
    "    nbr_samples = my_scene['nbr_samples']\n",
    "    print(description, \":\", nbr_samples, \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebe61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample example with its data\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "# The rendering command below is commented out because it tends to crash in notebooks\n",
    "# nusc.render_sample(first_sample_token)\n",
    "my_sample = nusc.get('sample', first_sample_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803ae69",
   "metadata": {},
   "source": [
    "Here, we look at different timestamps and see how the annotations around the car changes. This is important as external factors create a huge difference in safe driving. Not sure yet if this is relevent to the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a90699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed from `pedestrian.moving` to `pedestrian.standing` at timestamp 21 out of 39 annotated timestamps\n"
     ]
    }
   ],
   "source": [
    "def timestamp_change(my_instance):\n",
    "\n",
    "    first_token = my_instance['first_annotation_token']\n",
    "    last_token = my_instance['last_annotation_token']\n",
    "    nbr_samples = my_instance['nbr_annotations']\n",
    "    current_token = first_token\n",
    "\n",
    "    i = 0\n",
    "    found_change = False\n",
    "    while current_token != last_token:\n",
    "        current_ann = nusc.get('sample_annotation', current_token)\n",
    "        current_attr = nusc.get('attribute', current_ann['attribute_tokens'][0])['name']\n",
    "\n",
    "        if i == 0:\n",
    "            pass\n",
    "        elif current_attr != last_attr:\n",
    "            print(\"Changed from `{}` to `{}` at timestamp {} out of {} annotated timestamps\".format(last_attr, current_attr, i, nbr_samples))\n",
    "            found_change = True\n",
    "\n",
    "        next_token = current_ann['next']\n",
    "        current_token = next_token\n",
    "        last_attr = current_attr\n",
    "        i += 1\n",
    "        \n",
    "my_instance = nusc.instance[27]\n",
    "timestamp_change(my_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36a7df",
   "metadata": {},
   "source": [
    "Here we can calculate the visibility in the scene which is important when it comes to crashes and we can relate it to the factors we found from the crash data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245edf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = nusc.instance[27]\n",
    "\n",
    "def visibility(my_instance):\n",
    "    first_token = my_instance['first_annotation_token']\n",
    "    last_token = my_instance['last_annotation_token']\n",
    "    nbr_samples = my_instance['nbr_annotations']\n",
    "    current_token = first_token\n",
    "\n",
    "    i = 0\n",
    "    while current_token != last_token:\n",
    "\n",
    "        visibility_token = nusc.get('sample_annotation', current_token)['visibility_token']\n",
    "        current_ann = nusc.get('sample_annotation', current_token)\n",
    "\n",
    "        print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
    "        # nusc.render_annotation(current_token)\n",
    "\n",
    "        next_token = current_ann['next']\n",
    "        current_token = next_token\n",
    "        i += 1\n",
    "        \n",
    "# my_instance = nusc.instance[27]\n",
    "# visibility(my_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67732d4",
   "metadata": {},
   "source": [
    "Not sure if I need this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4060be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get calibrated sensor translation\n",
    "def cal_sensor_translation(cal_sens):\n",
    "    cal_sensor_token = nusc.get('calibrated_sensor', cal_sens)\n",
    "    cal_sensor_translation = cal_sensor_token['translation']\n",
    "    cal_sensor_translation = np.array(cal_sensor_translation)\n",
    "    return cal_sensor_translation\n",
    "\n",
    "# get ego pose sensor translation\n",
    "def ego_pose_translation(ego_sens):\n",
    "    ego_pose = nusc.get('ego_pose', ego_sens)\n",
    "    ego_pose_translation = ego_pose['translation']\n",
    "    ego_pose_translation = np.array(ego_pose_translation)\n",
    "    return ego_pose_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d8e96",
   "metadata": {},
   "source": [
    "Finding euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a20850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    \n",
    "    return math.dist(point1, point2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818de9b",
   "metadata": {},
   "source": [
    "Here we find the distance between a car and an annotation. This allows to check for safe distances for not only cars around but also surrounding inanimate objects and people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecf9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = euclidean_distance(ann_translation, ego_pose_trans)\n",
    "        distances.append(distance_ego_pose)\n",
    "    \n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95903ee",
   "metadata": {},
   "source": [
    "Lateral Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd76907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateral_distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = ego_pose_trans - ann_translation\n",
    "        distance_ego_pose = distance_ego_pose[0]\n",
    "        distances.append(distance_ego_pose)\n",
    "\n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d129b",
   "metadata": {},
   "source": [
    "Longtudinal Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0a6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longtudinal_distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = ego_pose_trans - ann_translation\n",
    "        distance_ego_pose = distance_ego_pose[1]\n",
    "        distances.append(distance_ego_pose)\n",
    "\n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1fd94",
   "metadata": {},
   "source": [
    "Finding velocities between each instance in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afe40a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'ca9a282c9e77460f8360f564131a8af5',\n",
       " 'timestamp': 1532402927647951,\n",
       " 'prev': '',\n",
       " 'next': '39586f9d59004284a7114a68825e8eec',\n",
       " 'scene_token': 'cc8c0bf57f984915a77078b10eb33198',\n",
       " 'data': {'RADAR_FRONT': '37091c75b9704e0daa829ba56dfa0906',\n",
       "  'RADAR_FRONT_LEFT': '11946c1461d14016a322916157da3c7d',\n",
       "  'RADAR_FRONT_RIGHT': '491209956ee3435a9ec173dad3aaf58b',\n",
       "  'RADAR_BACK_LEFT': '312aa38d0e3e4f01b3124c523e6f9776',\n",
       "  'RADAR_BACK_RIGHT': '07b30d5eb6104e79be58eadf94382bc1',\n",
       "  'LIDAR_TOP': '9d9bf11fb0e144c8b446d54a8a00184f',\n",
       "  'CAM_FRONT': 'e3d495d4ac534d54b321f50006683844',\n",
       "  'CAM_FRONT_RIGHT': 'aac7867ebf4f446395d29fbd60b63b3b',\n",
       "  'CAM_BACK_RIGHT': '79dbb4460a6b40f49f9c150cb118247e',\n",
       "  'CAM_BACK': '03bea5763f0f4722933508d5999c5fd8',\n",
       "  'CAM_BACK_LEFT': '43893a033f9c46d4a51b5e08a67a1eb7',\n",
       "  'CAM_FRONT_LEFT': 'fe5422747a7d4268a4b07fc396707b23'},\n",
       " 'anns': ['ef63a697930c4b20a6b9791f423351da',\n",
       "  '6b89da9bf1f84fd6a5fbe1c3b236f809',\n",
       "  '924ee6ac1fed440a9d9e3720aac635a0',\n",
       "  '91e3608f55174a319246f361690906ba',\n",
       "  'cd051723ed9c40f692b9266359f547af',\n",
       "  '36d52dfedd764b27863375543c965376',\n",
       "  '70af124fceeb433ea73a79537e4bea9e',\n",
       "  '63b89fe17f3e41ecbe28337e0e35db8e',\n",
       "  'e4a3582721c34f528e3367f0bda9485d',\n",
       "  'fcb2332977ed4203aa4b7e04a538e309',\n",
       "  'a0cac1c12246451684116067ae2611f6',\n",
       "  '02248ff567e3497c957c369dc9a1bd5c',\n",
       "  '9db977e264964c2887db1e37113cddaa',\n",
       "  'ca9c5dd6cf374aa980fdd81022f016fd',\n",
       "  '179b8b54ee74425893387ebc09ee133d',\n",
       "  '5b990ac640bf498ca7fd55eaf85d3e12',\n",
       "  '16140fbf143d4e26a4a7613cbd3aa0e8',\n",
       "  '54939f11a73d4398b14aeef500bf0c23',\n",
       "  '83d881a6b3d94ef3a3bc3b585cc514f8',\n",
       "  '74986f1604f047b6925d409915265bf7',\n",
       "  'e86330c5538c4858b8d3ffe874556cc5',\n",
       "  'a7bd5bb89e27455bbb3dba89a576b6a1',\n",
       "  'fbd9d8c939b24f0eb6496243a41e8c41',\n",
       "  '198023a1fb5343a5b6fad033ab8b7057',\n",
       "  'ffeafb90ecd5429cba23d0be9a5b54ee',\n",
       "  'cc636a58e27e446cbdd030c14f3718fd',\n",
       "  '076a7e3ec6244d3b84e7df5ebcbac637',\n",
       "  '0603fbaef1234c6c86424b163d2e3141',\n",
       "  'd76bd5dcc62f4c57b9cece1c7bcfabc5',\n",
       "  '5acb6c71bcd64aa188804411b28c4c8f',\n",
       "  '49b74a5f193c4759b203123b58ca176d',\n",
       "  '77519174b48f4853a895f58bb8f98661',\n",
       "  'c5e9455e98bb42c0af7d1990db1df0c9',\n",
       "  'fcc5b4b5c4724179ab24962a39ca6d65',\n",
       "  '791d1ca7e228433fa50b01778c32449a',\n",
       "  '316d20eb238c43ef9ee195642dd6e3fe',\n",
       "  'cda0a9085607438c9b1ea87f4360dd64',\n",
       "  'e865152aaa194f22b97ad0078c012b21',\n",
       "  '7962506dbc24423aa540a5e4c7083dad',\n",
       "  '29cca6a580924b72a90b9dd6e7710d3e',\n",
       "  'a6f7d4bb60374f868144c5ba4431bf4c',\n",
       "  'f1ae3f713ba946069fa084a6b8626fbf',\n",
       "  'd7af8ede316546f68d4ab4f3dbf03f88',\n",
       "  '91cb8f15ed4444e99470d43515e50c1d',\n",
       "  'bc638d33e89848f58c0b3ccf3900c8bb',\n",
       "  '26fb370c13f844de9d1830f6176ebab6',\n",
       "  '7e66fdf908d84237943c833e6c1b317a',\n",
       "  '67c5dbb3ddcc4aff8ec5140930723c37',\n",
       "  'eaf2532c820740ae905bb7ed78fb1037',\n",
       "  '3e2d17fa9aa5484d9cabc1dfca532193',\n",
       "  'de6bd5ffbed24aa59c8891f8d9c32c44',\n",
       "  '9d51d699f635478fbbcd82a70396dd62',\n",
       "  'b7cbc6d0e80e4dfda7164871ece6cb71',\n",
       "  '563a3f547bd64a2f9969278c5ef447fd',\n",
       "  'df8917888b81424f8c0670939e61d885',\n",
       "  'bb3ef5ced8854640910132b11b597348',\n",
       "  'a522ce1d7f6545d7955779f25d01783b',\n",
       "  '1fafb2468af5481ca9967407af219c32',\n",
       "  '05de82bdb8484623906bb9d97ae87542',\n",
       "  'bfedb0d85e164b7697d1e72dd971fb72',\n",
       "  'ca0f85b4f0d44beb9b7ff87b1ab37ff5',\n",
       "  'bca4bbfdef3d4de980842f28be80b3ca',\n",
       "  'a834fb0389a8453c810c3330e3503e16',\n",
       "  '6c804cb7d78943b195045082c5c2d7fa',\n",
       "  'adf1594def9e4722b952fea33b307937',\n",
       "  '49f76277d07541c5a584aa14c9d28754',\n",
       "  '15a3b4d60b514db5a3468e2aef72a90c',\n",
       "  '18cc2837f2b9457c80af0761a0b83ccc',\n",
       "  '2bfcc693ae9946daba1d9f2724478fd4']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding velocity from scenes\n",
    "\n",
    "def vector_velocities(sample_data_token):\n",
    "    \n",
    "    sample_data = nusc.get('sample_data', sample_data_token)\n",
    "    #print(sample_data['next'])\n",
    "    sample_data_token_prev = sample_data['prev']\n",
    "    #print(sample_data_token_prev)\n",
    "    sample_data_token_next = sample_data['next']\n",
    "    #print(sample_data_token_prev)\n",
    "\n",
    "    velocity = np.zeros(3)\n",
    "\n",
    "    #check if there are no previous or next ann as there will be no velocity \n",
    "    if not sample_data_token_prev or not sample_data_token_next:\n",
    "        velocity[velocity==0] = np.nan\n",
    "    else:\n",
    "        sample_data_prev = nusc.get('sample_data', sample_data_token_prev)\n",
    "        sample_data_next = nusc.get('sample_data', sample_data_token_next)\n",
    "        ego_pose_prev = nusc.get('ego_pose', sample_data_prev['ego_pose_token'])\n",
    "        ego_pose_next = nusc.get('ego_pose', sample_data_next['ego_pose_token'])\n",
    "        \n",
    "        ego_pose_trans_prev = np.array(ego_pose_prev['translation'])\n",
    "        ego_pose_trans_next = np.array(ego_pose_next['translation'])\n",
    "        \n",
    "        time_change = ego_pose_next['timestamp'] - ego_pose_prev['timestamp']\n",
    "        time_change = time_change * 1e-6 # convert ms to s\n",
    "        vel = ego_pose_trans_next - ego_pose_trans_prev\n",
    "\n",
    "        if time_change == 0:\n",
    "            pass\n",
    "        else:\n",
    "            vel = vel / time_change\n",
    "            \n",
    "        return vel # in m/s \n",
    "\n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "#print(first_sample_token)\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample\n",
    "\n",
    "#vector_velocities(first_sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a58dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding velocity from scenes\n",
    "\n",
    "def velocities(sample_data_token):\n",
    "    \n",
    "    sample_data = nusc.get('sample_data', sample_data_token)\n",
    "    #print(sample_data)\n",
    "\n",
    "    sample_data_token_prev = sample_data['prev']\n",
    "    sample_data_token_next = sample_data['next']\n",
    "\n",
    "    velocity = np.zeros(3)\n",
    "\n",
    "    #check if there are no previous or next ann as there will be no velocity \n",
    "    if not sample_data_token_prev or not sample_data_token_next:\n",
    "        velocity[velocity==0] = np.nan\n",
    "    else:\n",
    "        sample_data_prev = nusc.get('sample_data', sample_data_token_prev)\n",
    "        sample_data_next = nusc.get('sample_data', sample_data_token_next)\n",
    "\n",
    "        ego_pose_prev = nusc.get('ego_pose', sample_data_prev['ego_pose_token'])\n",
    "        ego_pose_next = nusc.get('ego_pose', sample_data_next['ego_pose_token'])\n",
    "        \n",
    "        ego_pose_trans_prev = np.array(ego_pose_prev['translation'])\n",
    "        ego_pose_trans_next = np.array(ego_pose_next['translation'])\n",
    "        \n",
    "        time_change = ego_pose_next['timestamp'] - ego_pose_prev['timestamp']\n",
    "        time_change = time_change / 3.6e+6 # convert to hours\n",
    "\n",
    "        distance = euclidean_distance(ego_pose_trans_next, ego_pose_trans_prev)\n",
    "\n",
    "        if time_change == 0:\n",
    "            pass\n",
    "        else:\n",
    "            velocity = distance / time_change\n",
    "            \n",
    "        return velocity, time_change #kmph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3857a87",
   "metadata": {},
   "source": [
    "Testing velocity function. The first image of the scene is being printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef1253f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31.705320917907336, 0.027652777777777776)\n",
      "(31.171686486397686, 0.027815833333333335)\n",
      "(29.707183618020554, 0.027803055555555557)\n",
      "(29.429907278884077, 0.027803333333333333)\n",
      "(27.21309976090792, 0.027803055555555557)\n",
      "(27.11982362650768, 0.027811944444444445)\n",
      "(25.70124619327095, 0.02780111111111111)\n",
      "(24.38688317901335, 0.02779861111111111)\n",
      "(24.14330897550741, 0.027655555555555555)\n",
      "(23.3445723185823, 0.027652777777777776)\n",
      "(22.475954016939507, 0.02780611111111111)\n",
      "(20.858546342095845, 0.02780111111111111)\n",
      "(19.674892290935166, 0.027801666666666666)\n",
      "(19.191320333736122, 0.02779888888888889)\n",
      "(18.461214013533954, 0.02781222222222222)\n",
      "(17.430558282078852, 0.027799444444444446)\n",
      "(16.528665412547294, 0.027779444444444443)\n",
      "(15.161421763056838, 0.027794444444444445)\n",
      "(15.780043578508254, 0.027644722222222223)\n",
      "(15.661327581609312, 0.027640555555555557)\n",
      "(15.73772265059839, 0.0277975)\n",
      "(15.377120692971264, 0.027799722222222222)\n",
      "(14.963616910821974, 0.027643333333333332)\n",
      "(13.791334939471044, 0.027795833333333332)\n",
      "(12.646841790033442, 0.02780583333333333)\n",
      "(11.090205614992087, 0.027651111111111112)\n",
      "(10.013376190715652, 0.027795277777777776)\n",
      "(9.156406505701813, 0.02780222222222222)\n",
      "(9.23300660250884, 0.027658055555555557)\n",
      "(8.337673940060125, 0.0277975)\n",
      "(8.441543309721931, 0.0276525)\n",
      "(8.517042912136285, 0.027806388888888887)\n",
      "(7.991951052342841, 0.027808055555555555)\n",
      "(8.164678089181114, 0.0278025)\n",
      "(8.733192387191593, 0.027643611111111112)\n",
      "(8.811636225841212, 0.02764861111111111)\n",
      "(8.19778243853484, 0.027667777777777777)\n"
     ]
    }
   ],
   "source": [
    "#test velocity changes in a scene\n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "#nusc.render_sample_data(my_sample_token)\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    \n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    #nusc.render_sample_data(my_sample_token)\n",
    "    print(velocities(my_sample_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa384ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    \n",
    "#     my_sample = nusc.get('sample', my_sample['next'])\n",
    "#     my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "#     #nusc.render_sample_data(my_sample_token)\n",
    "#     print(vector_velocities(my_sample_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3e696",
   "metadata": {},
   "source": [
    "Each sensor changes the velocities but not by a significant amount. Usually less than 0.2kmph so it does not affect the study in a significant way. In our study, we will pick one sensor for both velocity and acceleration to maintain consistency. We will pick the middle sensor as it is centralised and give the most consistant velocity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e4ec2",
   "metadata": {},
   "source": [
    "Finding acceleration between each instance in a scene and comparing to velocities etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f54e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceleration(v, v_0, delta_t):\n",
    "    return (v-v_0)/delta_t*7.7160494e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485762aa",
   "metadata": {},
   "source": [
    "Testing acceleration, looks slightly odd ngl. The velocities are very consistant but these are not. Can make sense. Might be better to look at acceleration over the whole scene rather than just an instance. \n",
    "\n",
    "NOTE: FOR TIME, USE TIME LENGTH OF SCENE. THIS WILL BE HOW MANY SECONDS THE SCENE IS - to be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c4b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63055556e-04 1.27777778e-05 2.77777778e-07 2.77777778e-07\n",
      " 8.88888889e-06 1.08333333e-05 2.50000000e-06 1.43055556e-04\n",
      " 2.77777778e-06 1.53333333e-04 5.00000000e-06 5.55555556e-07\n",
      " 2.77777778e-06 1.33333333e-05 1.27777778e-05 2.00000000e-05\n",
      " 1.50000000e-05 1.49722222e-04 4.16666667e-06 1.56944444e-04\n",
      " 2.22222222e-06 1.56388889e-04 1.52500000e-04 1.00000000e-05\n",
      " 1.54722222e-04 1.44166667e-04 6.94444444e-06 1.44166667e-04\n",
      " 1.39444444e-04 1.45000000e-04 1.53888889e-04 1.66666667e-06\n",
      " 5.55555556e-06 1.58888889e-04 5.00000000e-06 1.91666667e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.25252433877767433,\n",
       " -8.843616374743764,\n",
       " -77.02120548867316,\n",
       " -615.7798674874921,\n",
       " -0.8096886684825031,\n",
       " -10.103827894687587,\n",
       " -40.56675979019396,\n",
       " -0.13137767208821213,\n",
       " -22.187129408723155,\n",
       " -0.43710663425346646,\n",
       " -24.959995038058022,\n",
       " -164.39639636273648,\n",
       " -13.432554396741674,\n",
       " -4.225152325450015,\n",
       " -6.223766508236807,\n",
       " -3.479524967406167,\n",
       " -7.033146360869237,\n",
       " 0.3188114908457704,\n",
       " -2.1984443919422016,\n",
       " 0.03755903105221405,\n",
       " -12.520901334540385,\n",
       " -0.20401804967216078,\n",
       " -0.5931400394539785,\n",
       " -8.830965679022484,\n",
       " -0.7762997100180777,\n",
       " -0.5763377363993537,\n",
       " -9.52188541037114,\n",
       " 0.04099769694851902,\n",
       " -0.4954253344700513,\n",
       " 0.05527318534188718,\n",
       " 0.03785579752480623,\n",
       " -24.309808378217053,\n",
       " 2.398986628128285,\n",
       " 0.2760850326748012,\n",
       " 1.2105530682926502,\n",
       " -2.4712310333389014]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acceleration at each instance in a scene\n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "\n",
    "v_vector = []\n",
    "time_vector = []\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    #nusc.render_sample_data(my_sample_token)\n",
    "    v = velocities(my_sample_token)\n",
    "    v_vector.append(v[0])\n",
    "    time_vector.append(v[1])\n",
    "    \n",
    "#v_vector = [x / 3.6 for x in v_vector]\n",
    "#time_vector = [x  for x in time_vector]\n",
    "# print(len(time_vector))\n",
    "# print(sum(time_vector))\n",
    "#time_vector\n",
    "#print(v_vector, len(time_vector))\n",
    "\n",
    "change_time = abs(np.subtract(time_vector[1:len(time_vector)], time_vector[0:len(time_vector)-1]))\n",
    "print(change_time)\n",
    "a_vector = []\n",
    "for i in range(len(v_vector)-1):\n",
    "    a = acceleration(v_vector[i+1], v_vector[i], change_time[i])\n",
    "    a_vector.append(a)\n",
    "a_vector \n",
    "\n",
    "# time = time_vector[1] - time_vector[0]\n",
    "# print(acceleration(v_vector[0], v_vector[-1], time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9deb673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3264935907226303"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test overall acceleration in a scene\n",
    "\n",
    "a = acceleration(v_vector[len(v_vector)-1], v_vector[0], 20/3600) #convert seconds into hours\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc67ec",
   "metadata": {},
   "source": [
    "Using the box velocity function from github and altering it to find the velocity of annotations in a scene. We can then use this to find the minimum lateral and longitudinal distances between cars and whether it is safe or unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c84f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nutonomy/nuscenes-devkit/blob/master/python-sdk/nuscenes/nuscenes.py#L326\n",
    "\n",
    "def box_velocity(sample_annotation_token, max_time_diff):\n",
    "    \"\"\"\n",
    "    Estimate the velocity for an annotation.\n",
    "    If possible, we compute the centered difference between the previous and next frame.\n",
    "    Otherwise we use the difference between the current and previous/next frame.\n",
    "    If the velocity cannot be estimated, values are set to np.nan.\n",
    "    :param sample_annotation_token: Unique sample_annotation identifier.\n",
    "    :param max_time_diff: Max allowed time diff between consecutive samples that are used to estimate velocities.\n",
    "    :return: <np.float: 3>. Velocity in x/y/z direction in m/s.\n",
    "    \"\"\"\n",
    "\n",
    "    current =  nusc.get('sample_annotation', sample_annotation_token)\n",
    "    #current = sample_annotation_token\n",
    "    has_prev = current['prev'] != ''\n",
    "    has_next = current['next'] != ''\n",
    "\n",
    "    # Cannot estimate velocity for a single annotation.\n",
    "    if not has_prev and not has_next:\n",
    "        return 0\n",
    "\n",
    "    if has_prev:\n",
    "        first = nusc.get('sample_annotation', current['prev'])\n",
    "    else:\n",
    "        first = current\n",
    "\n",
    "    if has_next:\n",
    "        last = nusc.get('sample_annotation', current['next'])\n",
    "    else:\n",
    "        last = current\n",
    "\n",
    "    pos_last = np.array(last['translation'])\n",
    "    pos_first = np.array(first['translation'])\n",
    "    dist = euclidean_distance(pos_last, pos_first)\n",
    "    pos_diff = pos_last - pos_first\n",
    "\n",
    "    time_last = nusc.get('sample', last['sample_token'])['timestamp'] * 1e-6\n",
    "    time_first = nusc.get('sample', first['sample_token'])['timestamp'] * 1e-6\n",
    "    time_diff = time_last - time_first\n",
    "\n",
    "    if has_next and has_prev:\n",
    "        # If doing centered difference, allow for up to double the max_time_diff.\n",
    "        max_time_diff *= 2\n",
    "\n",
    "    if time_diff > max_time_diff:\n",
    "        # If time_diff is too big, don't return an estimate.\n",
    "        return np.array([np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        vel = dist / time_diff\n",
    "        return vel #in m/s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7debb91",
   "metadata": {},
   "source": [
    "Test to find velocities of annotations in a scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e91a9a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.020004158884655832, 1.2597506886115197, 0.056154349936019914, 1.4244997920574547, 0.10404085919030133, 0.15003119163491851, 0.9942087090563326, 9.57392544726772, 1.4329499979063416, 0.06801414020782982, 0.08001663553862333, 1.1406054945634099, 1.6643315930644524, 1.3053047070626935, 0, 0.036007485992380496, 1.707256226235029, 0.010002079442327916, 0.03499298644577765, 0.06801414020782982, 1.1797129400398527, 0.06601372431936424, 0.05001039721163958, 0.05001039721163958, 0.07047031066307531, 0.040849648396120354, 9.740254416497214, 0, 1.4712661082940677, 0.030006238326983747, 0.0, 1.523455592261911, 0.04200873365777714, 1.237512306304762, 1.3764547606452147, 0.06801414020782982, 11.258266155374152, 0.05001039721163958, 0.05001039721163958, 2.724881465349411, 0.0, 0.06601372431936424, 0.05001039721163958, 0.0, 0.03400707010391469, 0.45367121405464356, 1.5407787027769209, 1.1907701366380175, 1.3154373488583346, 0.05001039721163958, 1.139248703386448, 0.04635615839674824, 3.2318035854911784, 0.9262703230428116, 0.13705403873554378, 0.8767665606779982, 1.2899968452676565, 1.3007164975755376, 0.04708419803577588, 0.19325508418265783, 0.08001663553862333, 0.05001039721163958, 1.3516536456539745, 0.029738320121387517, 0.05001039721163936, 5.183761569923071, 0.07201497198476099, 0.058046540448048425, 0.10002079442327894]\n"
     ]
    }
   ],
   "source": [
    "my_scene = nusc.scene[0]\n",
    "sample_token = my_scene['first_sample_token']\n",
    "\n",
    "my_sample = nusc.get('sample', sample_token)\n",
    "anns = my_sample['anns']\n",
    "max_time_diff = 1.5\n",
    "\n",
    "ann_velocities = []\n",
    "\n",
    "for i in range(len(anns)):\n",
    "    ann = anns[i]\n",
    "    ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "    velocity = box_velocity(ann, max_time_diff)\n",
    "    ann_velocities.append(velocity)\n",
    "    #nusc.render makes the notebook crash, not an error in the code, uncomment to see images\n",
    "    #nusc.render_instance(ann_metadata['instance_token'])\n",
    "    \n",
    "print(ann_velocities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3297243",
   "metadata": {},
   "source": [
    "Finding minimum longitudinal and lateral distances according to RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fce6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do not hit the car in front (longtudinal distance)\n",
    "def d_min_longtudinal(v_r, v_f, p = 0.53, acc_max= 4.10, break_min = 4.64, break_max = 8.03):\n",
    "    \n",
    "    d_min = v_r*p + 0.5*acc_max*(p)**2 + (v_r + p*acc_max)**2/(2*break_min) - (v_f)**2/(2*break_max)\n",
    "\n",
    "    if d_min < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return d_min\n",
    "\n",
    "# Do not cut in recklessly (lateral distance)\n",
    "def d_min_lateral(v1, v2, mu = 0.07, p = 0.53, acc_max = 0.43, break_min = 0.96, break_min_correct = 1.76):\n",
    "    \n",
    "    v1_p = v1 + p*acc_max\n",
    "    v2_p = v2 - p*acc_max\n",
    "    \n",
    "    d_min = mu + ((v1+v1_p)*0.5*p + (v1_p**2)/(2*break_min)-(((v2+v1_p)/2)*p + v2_p**2/(2*break_min_correct)))\n",
    "    d_min = max(0, d_min)\n",
    "\n",
    "    return d_min\n",
    "    \n",
    "# NOTE: d_min_lateral is >= not >.\n",
    " \n",
    "# min and max values\n",
    "# Defns: file:///afs/inf.ed.ac.uk/user/s19/s1945293/Downloads/FRAV-02-04.pdf\n",
    "# https://intel.github.io/ad-rss-lib/ad_rss/Appendix-ParameterDiscussion/ \n",
    "# https://static.mobileye.com/website/corporate/rss/rss_on_nhtsa.pdf\n",
    "# https://www.google.com/search?q=minimum+safe+distance+cars&tbm=isch&ved=2ahUKEwjj4dSa6OD8AhVsnCcCHVHtCooQ2-cCegQIABAA&oq=minimum+safe+distance+cars&gs_lcp=CgNpbWcQAzoECCMQJzoECAAQQzoFCAAQgAQ6BggAEAgQHjoHCAAQgAQQGFDJBViHC2C2DWgAcAB4AIABR4gB5QKSAQE2mAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=diDQY-POEuy4nsEP0dqr0Ag&bih=1088&biw=1920&client=ubuntu&hs=ixR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28eb3e3",
   "metadata": {},
   "source": [
    "Test whether distances are safe by finding min distances and comparing to actual distances. Do I need to compare with inanimate objects and pedestrians or only cars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e4d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Safe Long Dist</th>\n",
       "      <th>Actual Long Dist</th>\n",
       "      <th>Safe Lat Dist</th>\n",
       "      <th>Actual Lat Dist</th>\n",
       "      <th>Safe Long</th>\n",
       "      <th>Safe Lat</th>\n",
       "      <th>Safe Overall</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.946910</td>\n",
       "      <td>36.487152</td>\n",
       "      <td>0.872221</td>\n",
       "      <td>46.257973</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.939989</td>\n",
       "      <td>31.088152</td>\n",
       "      <td>0.796183</td>\n",
       "      <td>23.913973</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.946898</td>\n",
       "      <td>55.967152</td>\n",
       "      <td>0.870906</td>\n",
       "      <td>44.313973</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.938090</td>\n",
       "      <td>33.344152</td>\n",
       "      <td>0.781692</td>\n",
       "      <td>17.511973</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.946863</td>\n",
       "      <td>-0.328848</td>\n",
       "      <td>0.868972</td>\n",
       "      <td>-20.103027</td>\n",
       "      <td>Not Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Not Safe</td>\n",
       "      <td>Longtudinally Not Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>1.259391</td>\n",
       "      <td>70.837983</td>\n",
       "      <td>0.581150</td>\n",
       "      <td>-25.320715</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>1.259391</td>\n",
       "      <td>-16.347017</td>\n",
       "      <td>0.580667</td>\n",
       "      <td>2.290285</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>1.258891</td>\n",
       "      <td>73.992983</td>\n",
       "      <td>0.566723</td>\n",
       "      <td>-27.093715</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>1.253838</td>\n",
       "      <td>-14.211017</td>\n",
       "      <td>0.515340</td>\n",
       "      <td>-11.314715</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>1.259199</td>\n",
       "      <td>-33.861017</td>\n",
       "      <td>0.572743</td>\n",
       "      <td>16.556285</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Safe</td>\n",
       "      <td>Longtudianally and Laterally Safe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4553 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Safe Long Dist  Actual Long Dist  Safe Lat Dist  Actual Lat Dist  \\\n",
       "0           3.946910         36.487152       0.872221        46.257973   \n",
       "1           3.939989         31.088152       0.796183        23.913973   \n",
       "2           3.946898         55.967152       0.870906        44.313973   \n",
       "3           3.938090         33.344152       0.781692        17.511973   \n",
       "4           3.946863         -0.328848       0.868972       -20.103027   \n",
       "...              ...               ...            ...              ...   \n",
       "4548        1.259391         70.837983       0.581150       -25.320715   \n",
       "4549        1.259391        -16.347017       0.580667         2.290285   \n",
       "4550        1.258891         73.992983       0.566723       -27.093715   \n",
       "4551        1.253838        -14.211017       0.515340       -11.314715   \n",
       "4552        1.259199        -33.861017       0.572743        16.556285   \n",
       "\n",
       "     Safe Long Safe Lat Safe Overall                        Description  \n",
       "0         Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "1         Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "2         Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "3         Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "4     Not Safe     Safe     Not Safe             Longtudinally Not Safe  \n",
       "...        ...      ...          ...                                ...  \n",
       "4548      Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "4549      Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "4550      Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "4551      Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "4552      Safe     Safe         Safe  Longtudianally and Laterally Safe  \n",
       "\n",
       "[4553 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test velocity changes in a scene   \n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "#my_sample = nusc.get('sample', my_sample['next'])\n",
    "#print(my_sample_token)\n",
    "sample_data = nusc.get('sample_data', my_sample_token)\n",
    "first_sample_data_token = sample_data['sample_token']\n",
    "anns = my_sample['anns']\n",
    "max_time_diff = 1.5\n",
    "ann_velocities = []\n",
    "\n",
    "actual_vels_lat = []\n",
    "actual_vels_long = []\n",
    "\n",
    "#actual_vels_lat = lateral_distance(first_sample_token)\n",
    "#actual_vels_long = longtudinal_distance(first_sample_token)\n",
    "\n",
    "rss_lat = []\n",
    "rss_long = []\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "\n",
    "    #get next token in the scene\n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    anns = my_sample['anns']\n",
    "    max_time_diff = 1.5\n",
    "    ann_velocities = []\n",
    "    actual_vels_lat.extend(lateral_distance(my_sample['token']))\n",
    "    actual_vels_long.extend(longtudinal_distance(my_sample['token']))\n",
    "\n",
    "    #nusc.render_sample_data(my_sample_token) #shows how the car moves throughout the scene.\n",
    "    vel_lat = abs(vector_velocities(my_sample_token)[0])\n",
    "    vel_long = abs(vector_velocities(my_sample_token)[1])\n",
    "\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata = nusc.get('sample_annotation', ann)\n",
    "        velocity = box_velocity(ann, max_time_diff)\n",
    "        ann_velocities.append(velocity)\n",
    "\n",
    "        rss_long.append(d_min_longtudinal(vel_long/3.6, ann_velocities[i]/3.6))\n",
    "        rss_lat.append(d_min_lateral(vel_lat/3.6, ann_velocities[i]/3.6))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Safe Long Dist'] = rss_long\n",
    "df['Actual Long Dist'] = actual_vels_lat\n",
    "df['Safe Lat Dist'] = rss_lat\n",
    "df['Actual Lat Dist'] = actual_vels_long\n",
    "df['Safe Long'] = np.where((df['Safe Long Dist'] <= abs(df['Actual Long Dist'])), 'Safe', 'Not Safe')\n",
    "df['Safe Lat'] = np.where((df['Safe Lat Dist'] <= abs(df['Actual Lat Dist'])), 'Safe', 'Not Safe')\n",
    "df['Safe Overall'] = np.where(((df['Safe Long'] == 'Not Safe') | (df['Safe Lat'] == 'Not Safe')), 'Not Safe', 'Safe')\n",
    "\n",
    "conditions = [\n",
    "    #(df['Safe Long'] == 'Safe'),\n",
    "    (df['Safe Long'] == 'Not Safe'),\n",
    "    #(df['Safe Lat'] == 'Safe'),\n",
    "    (df['Safe Lat'] == 'Not Safe'),\n",
    "    (df['Safe Overall'] == 'Safe'),\n",
    "    (df['Safe Lat'] == 'Not Safe') & (df['Safe Long'] == 'Not Safe')\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['Longtudinally Not Safe', 'Laterally Not Safe', 'Longtudianally and Laterally Safe', 'Longtudianally and Laterally Unsafe']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['Description'] = np.select(conditions, values)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1a85fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.16933889743026 98.48451570393148 91.65385460136174\n"
     ]
    }
   ],
   "source": [
    "if (\"Safe\" in df['Safe Long'].values) == True:\n",
    "    safe_long = df['Safe Long'].value_counts()['Safe']\n",
    "if (\"Safe\" in df['Safe Long'].values)== False:\n",
    "    safe_long = 0\n",
    "if (\"Not Safe\" in df['Safe Long'].values) == True:\n",
    "    not_safe_long = df['Safe Long'].value_counts()['Not Safe']\n",
    "if (\"Not Safe\" in df[\"Safe Long\"].values) == False:\n",
    "    not_safe_long = 0\n",
    "    \n",
    "safe_long_percent = safe_long/(safe_long + not_safe_long) *100\n",
    "\n",
    "if (\"Safe\" in df['Safe Lat'].values) == True:\n",
    "    safe_lat = df['Safe Lat'].value_counts()['Safe']\n",
    "if (\"Safe\" in df['Safe Lat'].values) == False:\n",
    "    safe_lat = 0\n",
    "if (\"Not Safe\" in df['Safe Lat'].values) == True:\n",
    "    not_safe_lat = df['Safe Lat'].value_counts()['Not Safe']\n",
    "if (\"Not Safe\" in df[\"Safe Lat\"].values) == False:\n",
    "    not_safe_lat = 0\n",
    "\n",
    "safe_lat_percent = safe_lat/(safe_lat + not_safe_lat) * 100\n",
    "\n",
    "if (\"Safe\" in df['Safe Overall'].values) == True:\n",
    "    safe_overall = df['Safe Overall'].value_counts()['Safe']\n",
    "if (\"Safe\" in df['Safe Overall'].values) == False:\n",
    "    safe_overall = 0\n",
    "if (\"Not Safe\" in df['Safe Overall'].values) == True:\n",
    "    not_safe_overall = df['Safe Overall'].value_counts()['Not Safe']\n",
    "if (\"Not Safe\" in df['Safe Overall'].values) == False:\n",
    "    not_safe_overall = 0\n",
    "\n",
    "safe_overall_percent = safe_overall/(safe_overall + not_safe_overall) * 100\n",
    "\n",
    "print(safe_long_percent, safe_lat_percent, safe_overall_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af78e006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene Names</th>\n",
       "      <th>Description</th>\n",
       "      <th>Vehicle Number</th>\n",
       "      <th>Location</th>\n",
       "      <th>Acceleration($m/s^2$)</th>\n",
       "      <th>Longitudinal Safety Percentage</th>\n",
       "      <th>Lateral Safety Percentage</th>\n",
       "      <th>Overall Safety Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scene-0061</td>\n",
       "      <td>Parked truck, construction, intersection, turn...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-onenorth</td>\n",
       "      <td>-3.264936e-01</td>\n",
       "      <td>93.169339</td>\n",
       "      <td>98.484516</td>\n",
       "      <td>91.653855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scene-0103</td>\n",
       "      <td>Many peds right, wait for turning car, long bi...</td>\n",
       "      <td>n008</td>\n",
       "      <td>boston-seaport</td>\n",
       "      <td>1.121252e-03</td>\n",
       "      <td>93.969352</td>\n",
       "      <td>95.600593</td>\n",
       "      <td>89.569946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scene-0553</td>\n",
       "      <td>Wait at intersection, bicycle, large truck, pe...</td>\n",
       "      <td>n008</td>\n",
       "      <td>boston-seaport</td>\n",
       "      <td>9.456827e-08</td>\n",
       "      <td>99.005236</td>\n",
       "      <td>95.547774</td>\n",
       "      <td>99.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scene-0655</td>\n",
       "      <td>Parking lot, parked cars, jaywalker, bendy bus...</td>\n",
       "      <td>n008</td>\n",
       "      <td>boston-seaport</td>\n",
       "      <td>4.537465e-02</td>\n",
       "      <td>97.345518</td>\n",
       "      <td>95.039164</td>\n",
       "      <td>92.384682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scene-0757</td>\n",
       "      <td>Arrive at busy intersection, bus, wait at inte...</td>\n",
       "      <td>n008</td>\n",
       "      <td>boston-seaport</td>\n",
       "      <td>-2.570399e-01</td>\n",
       "      <td>95.352840</td>\n",
       "      <td>98.106713</td>\n",
       "      <td>93.459552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scene-0796</td>\n",
       "      <td>Scooter, peds on sidewalk, bus, cars, truck, f...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-queenstown</td>\n",
       "      <td>-3.972206e-02</td>\n",
       "      <td>91.994178</td>\n",
       "      <td>96.360990</td>\n",
       "      <td>88.355167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scene-0916</td>\n",
       "      <td>Parking lot, bicycle rack, parked bicycles, bu...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-queenstown</td>\n",
       "      <td>-3.324193e-02</td>\n",
       "      <td>92.415850</td>\n",
       "      <td>96.463571</td>\n",
       "      <td>88.879421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scene-1077</td>\n",
       "      <td>Night, big street, bus stop, high speed, const...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-hollandvillage</td>\n",
       "      <td>4.381411e-01</td>\n",
       "      <td>94.063927</td>\n",
       "      <td>92.465753</td>\n",
       "      <td>86.757991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scene-1094</td>\n",
       "      <td>Night, after rain, many peds, PMD, ped with ba...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-hollandvillage</td>\n",
       "      <td>6.218723e-01</td>\n",
       "      <td>91.286550</td>\n",
       "      <td>98.947368</td>\n",
       "      <td>90.292398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scene-1100</td>\n",
       "      <td>Night, peds in sidewalk, peds cross crosswalk,...</td>\n",
       "      <td>n015</td>\n",
       "      <td>singapore-hollandvillage</td>\n",
       "      <td>-4.423312e-05</td>\n",
       "      <td>99.451153</td>\n",
       "      <td>99.012075</td>\n",
       "      <td>98.463227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scene Names                                        Description  \\\n",
       "0  scene-0061  Parked truck, construction, intersection, turn...   \n",
       "1  scene-0103  Many peds right, wait for turning car, long bi...   \n",
       "2  scene-0553  Wait at intersection, bicycle, large truck, pe...   \n",
       "3  scene-0655  Parking lot, parked cars, jaywalker, bendy bus...   \n",
       "4  scene-0757  Arrive at busy intersection, bus, wait at inte...   \n",
       "5  scene-0796  Scooter, peds on sidewalk, bus, cars, truck, f...   \n",
       "6  scene-0916  Parking lot, bicycle rack, parked bicycles, bu...   \n",
       "7  scene-1077  Night, big street, bus stop, high speed, const...   \n",
       "8  scene-1094  Night, after rain, many peds, PMD, ped with ba...   \n",
       "9  scene-1100  Night, peds in sidewalk, peds cross crosswalk,...   \n",
       "\n",
       "  Vehicle Number                  Location  Acceleration($m/s^2$)  \\\n",
       "0           n015        singapore-onenorth          -3.264936e-01   \n",
       "1           n008            boston-seaport           1.121252e-03   \n",
       "2           n008            boston-seaport           9.456827e-08   \n",
       "3           n008            boston-seaport           4.537465e-02   \n",
       "4           n008            boston-seaport          -2.570399e-01   \n",
       "5           n015      singapore-queenstown          -3.972206e-02   \n",
       "6           n015      singapore-queenstown          -3.324193e-02   \n",
       "7           n015  singapore-hollandvillage           4.381411e-01   \n",
       "8           n015  singapore-hollandvillage           6.218723e-01   \n",
       "9           n015  singapore-hollandvillage          -4.423312e-05   \n",
       "\n",
       "   Longitudinal Safety Percentage  Lateral Safety Percentage  \\\n",
       "0                       93.169339                  98.484516   \n",
       "1                       93.969352                  95.600593   \n",
       "2                       99.005236                  95.547774   \n",
       "3                       97.345518                  95.039164   \n",
       "4                       95.352840                  98.106713   \n",
       "5                       91.994178                  96.360990   \n",
       "6                       92.415850                  96.463571   \n",
       "7                       94.063927                  92.465753   \n",
       "8                       91.286550                  98.947368   \n",
       "9                       99.451153                  99.012075   \n",
       "\n",
       "   Overall Safety Percentage  \n",
       "0                  91.653855  \n",
       "1                  89.569946  \n",
       "2                  99.005236  \n",
       "3                  92.384682  \n",
       "4                  93.459552  \n",
       "5                  88.355167  \n",
       "6                  88.879421  \n",
       "7                  86.757991  \n",
       "8                  90.292398  \n",
       "9                  98.463227  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test velocity changes in all scenes in mini dataset\n",
    "percentages_df = pd.DataFrame()\n",
    "safe_long_percentages = []\n",
    "safe_lat_percentages = []\n",
    "safe_overall_percentages = []\n",
    "scene_names = []\n",
    "locations = []\n",
    "descriptions = []\n",
    "vehicles = []\n",
    "max_time_diff = 1.5\n",
    "accel = []\n",
    "\n",
    "# Go through each scene in the mini dataset\n",
    "for scene in range(len(nusc.scene)):  \n",
    "    \n",
    "    #get all values and tokens needed and initialise values\n",
    "    my_scene = nusc.scene[scene]\n",
    "    scene_name = my_scene['name']\n",
    "    scene_names.append(scene_name)\n",
    "    first_sample_token = my_scene['first_sample_token']\n",
    "    my_sample = nusc.get('sample', first_sample_token)\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    sample_data = nusc.get('sample_data', my_sample_token)\n",
    "    first_sample_data_token = sample_data['sample_token']\n",
    "    anns = my_sample['anns']\n",
    "    ann_velocities = []\n",
    "    actual_vels_lat = []\n",
    "    actual_vels_long = []\n",
    "\n",
    "    #actual_vels_lat = lateral_distance(first_sample_token)\n",
    "    #actual_vels_long = longtudinal_distance(first_sample_token)\n",
    "\n",
    "    rss_lat = []\n",
    "    rss_long = []\n",
    "    accel_vels = []   \n",
    "\n",
    "    # Go through each token in a scene to then go through each annotation in that snippet\n",
    "    while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "\n",
    "        #get next token in the scene\n",
    "        my_sample = nusc.get('sample', my_sample['next'])\n",
    "        my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "        anns = my_sample['anns']\n",
    "        ann_velocities = []\n",
    "        actual_vels_lat.extend(lateral_distance(my_sample['token']))\n",
    "        actual_vels_long.extend(longtudinal_distance(my_sample['token']))\n",
    "\n",
    "        #nusc.render_sample_data(my_sample_token) #shows how the car moves throughout the scene.\n",
    "        vel_lat = abs(vector_velocities(my_sample_token)[0])\n",
    "        vel_long = abs(vector_velocities(my_sample_token)[1])\n",
    "        accel_vels.append(velocities(my_sample_token))\n",
    "        \n",
    "\n",
    "        for i in range(len(anns)):\n",
    "            ann = anns[i]\n",
    "            ann_metadata = nusc.get('sample_annotation', ann)\n",
    "            velocity = box_velocity(ann, max_time_diff)\n",
    "            ann_velocities.append(velocity)\n",
    "\n",
    "            rss_long.append(d_min_longtudinal(vel_long/3.6, ann_velocities[i]/3.6))\n",
    "            rss_lat.append(d_min_lateral(vel_lat/3.6, ann_velocities[i]/3.6))\n",
    "\n",
    "    vel_vals = [i[0] for i in accel_vels]\n",
    "    accel.append(acceleration(vel_vals[len(vel_vals)-1], vel_vals[0], 20/3600)) #convert seconds into hours\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['Safe Long Dist'] = rss_long\n",
    "    df['Actual Long Dist'] = actual_vels_lat\n",
    "    df['Safe Lat Dist'] = rss_lat\n",
    "    df['Actual Lat Dist'] = actual_vels_long\n",
    "    df['Safe Long'] = np.where((df['Safe Long Dist'] <= abs(df['Actual Long Dist'])), 'Safe', 'Not Safe')\n",
    "    df['Safe Lat'] = np.where((df['Safe Lat Dist'] <= abs(df['Actual Lat Dist'])), 'Safe', 'Not Safe')\n",
    "    df['Safe Overall'] = np.where(((df['Safe Long'] == 'Not Safe') | (df['Safe Lat'] == 'Not Safe')), 'Not Safe', 'Safe')\n",
    "\n",
    "    conditions = [\n",
    "        #(df['Safe Long'] == 'Safe'),\n",
    "        (df['Safe Long'] == 'Not Safe'),\n",
    "        #(df['Safe Lat'] == 'Safe'),\n",
    "        (df['Safe Lat'] == 'Not Safe'),\n",
    "        (df['Safe Overall'] == 'Safe'),\n",
    "        (df['Safe Lat'] == 'Not Safe') & (df['Safe Long'] == 'Not Safe')\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['Longtudinally Not Safe', 'Laterally Not Safe', 'Longtudianally and Laterally Safe', 'Longtudianally and Laterally Unsafe']\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['Description'] = np.select(conditions, values)\n",
    "\n",
    "    if (\"Safe\" in df['Safe Long'].values) == True:\n",
    "        safe_long = df['Safe Long'].value_counts()['Safe']\n",
    "    if (\"Safe\" in df['Safe Long'].values)== False:\n",
    "        safe_long = 0\n",
    "    if (\"Not Safe\" in df['Safe Long'].values) == True:\n",
    "        not_safe_long = df['Safe Long'].value_counts()['Not Safe']\n",
    "    if (\"Not Safe\" in df[\"Safe Long\"].values) == False:\n",
    "        not_safe_long = 0\n",
    "\n",
    "    safe_long_percent = safe_long/(safe_long + not_safe_long) *100\n",
    "\n",
    "    if (\"Safe\" in df['Safe Lat'].values) == True:\n",
    "        safe_lat = df['Safe Lat'].value_counts()['Safe']\n",
    "    if (\"Safe\" in df['Safe Lat'].values) == False:\n",
    "        safe_long = 0\n",
    "    if (\"Not Safe\" in df['Safe Lat'].values) == True:\n",
    "        not_safe_lat = df['Safe Lat'].value_counts()['Not Safe']\n",
    "    if (\"Not Safe\" in df[\"Safe Lat\"].values) == False:\n",
    "        not_safe_long = 0\n",
    "\n",
    "    safe_lat_percent = safe_lat/(safe_lat + not_safe_lat) * 100\n",
    "\n",
    "    if (\"Safe\" in df['Safe Overall'].values) == True:\n",
    "        safe_overall = df['Safe Overall'].value_counts()['Safe']\n",
    "    if (\"Safe\" in df['Safe Overall'].values) == False:\n",
    "        safe_overall = 0\n",
    "    if (\"Not Safe\" in df['Safe Overall'].values) == True:\n",
    "        not_safe_overall = df['Safe Overall'].value_counts()['Not Safe']\n",
    "    if (\"Not Safe\" in df['Safe Overall'].values) == False:\n",
    "        not_safe_overall = 0\n",
    "\n",
    "    safe_overall_percent = safe_overall/(safe_overall + not_safe_overall) * 100\n",
    "\n",
    "    safe_long_percentages.append(safe_long_percent)\n",
    "    safe_lat_percentages.append(safe_lat_percent)\n",
    "    safe_overall_percentages.append(safe_overall_percent)\n",
    "    \n",
    "    # Get scene locations\n",
    "    token = nusc.scene[scene]['log_token']\n",
    "    location = nusc.get('log', token)['location']\n",
    "    locations.append(location)\n",
    "    \n",
    "    # Get scene descriptions\n",
    "    description = nusc.scene[scene]['description']\n",
    "    descriptions.append(description)\n",
    "    \n",
    "    # Get scene vehicles\n",
    "    vehicle = nusc.get('log', token)['vehicle']\n",
    "    vehicles.append(vehicle)\n",
    "\n",
    "percentages_df['Scene Names'] = scene_names\n",
    "percentages_df['Description'] = descriptions\n",
    "percentages_df['Vehicle Number'] = vehicles \n",
    "percentages_df['Location'] = locations\n",
    "percentages_df['Acceleration($m/s^2$)'] = accel\n",
    "percentages_df['Longitudinal Safety Percentage'] = safe_long_percentages\n",
    "percentages_df['Lateral Safety Percentage'] = safe_lat_percentages\n",
    "percentages_df['Overall Safety Percentage'] = safe_overall_percentages\n",
    "percentages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d81d9",
   "metadata": {},
   "source": [
    "<b>Reminder</b>: The vehicle number is going to be the same for each location as they use the same car in each different city/area. \n",
    "\n",
    "Add <b>acceleration</b> to the dataframe with a safety percentage also. Here is an example of what is considered safe acceleration/decceleration:\n",
    "\n",
    "Many safety experts use 15 ft/sec2 (0.47 g's) as the maximum deceleration that is safe for the average driver to maintain control, good to excellent tires, dry surface. A reasonably skilled driver can stop at 20 ft/sec2 (0.62 g's). Most production street vehicles have a maximum braking around 0.8 g's.\n",
    "\n",
    "Another thing to add is <b>visibility</b> percentage throughout a scene. Get all the percentages and average them out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48867a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long = plt.scatter(percentages_df['Scene Names'], percentages_df['Longitudinal Safety Percentage'], s=60, c='purple')\n",
    "lat = plt.scatter(percentages_df['Scene Names'], percentages_df['Lateral Safety Percentage'], s=60, c='green')\n",
    "overall = plt.scatter(percentages_df['Scene Names'], percentages_df['Overall Safety Percentage'], s=60, c='red')\n",
    "\n",
    "plt.legend((long, lat, overall),\n",
    "           ('Longitudinal Safety Percentage', 'Lateral Safety Percentage', 'Overall Safety Percentage'),\n",
    "           scatterpoints=1,\n",
    "           loc='best',\n",
    "           fontsize=6)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Scene vs RSS Safety Percentages\")\n",
    "plt.xlabel(\"Scene\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb185352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "# create data\n",
    "x = np.arange(len(percentages_df['Scene Names']))\n",
    "y1 = [34, 56, 12, 89, 67]\n",
    "y2 = [12, 56, 78, 45, 90]\n",
    "y3 = [14, 23, 45, 25, 89]\n",
    "width = 0.2\n",
    "  \n",
    "# plot data in grouped manner of bar type\n",
    "plt.bar(x-0.2, percentages_df['Longitudinal Safety Percentage'], width)\n",
    "plt.bar(x, percentages_df['Lateral Safety Percentage'], width)\n",
    "plt.bar(x+0.2, percentages_df['Overall Safety Percentage'], width)\n",
    "plt.xticks(x, percentages_df['Scene Names'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Scene\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(\"Scene vs RSS Safety Percentages\")\n",
    "plt.legend((long, lat, overall),\n",
    "           ('Longitudinal Safety Percentage', 'Lateral Safety Percentage', 'Overall Safety Percentage'),\n",
    "           loc='best',\n",
    "           fontsize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ee8e7",
   "metadata": {},
   "source": [
    "Overall, we can see that longtudinal safety is lower than lateral safety as a general trend. However, most of the scenes have a generally high safety score in terms of RSS safety. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e776303",
   "metadata": {},
   "source": [
    "K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import sklearn\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# for i in range(len(percentages_df)):\n",
    "#     kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "#     kmeans.fit(percentages_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
