{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabeedea",
   "metadata": {},
   "source": [
    "# Understanding NuScenes dataset and creating functions\n",
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae38a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43736a",
   "metadata": {},
   "source": [
    "Load nuscnenes mini dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c025a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.366 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', dataroot='data/sets/nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d565",
   "metadata": {},
   "source": [
    "Look at what each scene contains based on description etc. Below, the city/area is significant to us as well as the roadway type/description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e5b2ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-0061, Parked truck, construction, intersectio... [18-07-24 03:28:47]   19s, singapore-onenorth, #anns:4622\n",
      "scene-0103, Many peds right, wait for turning car, ... [18-08-01 19:26:43]   19s, boston-seaport, #anns:2046\n",
      "scene-0655, Parking lot, parked cars, jaywalker, be... [18-08-27 15:51:32]   20s, boston-seaport, #anns:2332\n",
      "scene-0553, Wait at intersection, bicycle, large tr... [18-08-28 20:48:16]   20s, boston-seaport, #anns:1950\n",
      "scene-0757, Arrive at busy intersection, bus, wait ... [18-08-30 19:25:08]   20s, boston-seaport, #anns:592\n",
      "scene-0796, Scooter, peds on sidewalk, bus, cars, t... [18-10-02 02:52:24]   20s, singapore-queensto, #anns:708\n",
      "scene-0916, Parking lot, bicycle rack, parked bicyc... [18-10-08 07:37:13]   20s, singapore-queensto, #anns:2387\n",
      "scene-1077, Night, big street, bus stop, high speed... [18-11-21 11:39:27]   20s, singapore-hollandv, #anns:890\n",
      "scene-1094, Night, after rain, many peds, PMD, ped ... [18-11-21 11:47:27]   19s, singapore-hollandv, #anns:1762\n",
      "scene-1100, Night, peds in sidewalk, peds cross cro... [18-11-21 11:49:47]   19s, singapore-hollandv, #anns:935\n"
     ]
    }
   ],
   "source": [
    "nusc.list_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e188e",
   "metadata": {},
   "source": [
    "Below, we can see how many samples we have of each type of scenario/scene. This gives us a greater insight into what the dataset contains. The cell underneath then allows us to see the different information we can find within the dataset and allows us to explore NuScenes a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd608323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parked truck, construction, intersection, turn left, following a van : 39 samples\n",
      "Many peds right, wait for turning car, long bike rack left, cyclist : 40 samples\n",
      "Wait at intersection, bicycle, large truck, peds crossing crosswalk, ped with stroller : 41 samples\n",
      "Parking lot, parked cars, jaywalker, bendy bus, gardening vehicles : 41 samples\n",
      "Arrive at busy intersection, bus, wait at intersection, bicycle, peds : 41 samples\n",
      "Scooter, peds on sidewalk, bus, cars, truck, fake construction worker, bicycle, cross intersection, car overtaking us : 40 samples\n",
      "Parking lot, bicycle rack, parked bicycles, bus, many peds, parked scooters, parked motorcycle : 41 samples\n",
      "Night, big street, bus stop, high speed, construction vehicle : 41 samples\n",
      "Night, after rain, many peds, PMD, ped with bag, jaywalker, truck, scooter : 40 samples\n",
      "Night, peds in sidewalk, peds cross crosswalk, scooter, PMD, difficult lighting : 40 samples\n"
     ]
    }
   ],
   "source": [
    "# Sample type and number of that sample\n",
    "for i in range(len(nusc.scene)):\n",
    "    my_scene = nusc.scene[i]\n",
    "    description = my_scene['description']\n",
    "    nbr_samples = my_scene['nbr_samples']\n",
    "    print(description, \":\", nbr_samples, \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebe61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample example with its data\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "# The rendering command below is commented out because it tends to crash in notebooks\n",
    "# nusc.render_sample(first_sample_token)\n",
    "my_sample = nusc.get('sample', first_sample_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803ae69",
   "metadata": {},
   "source": [
    "Here, we look at different timestamps and see how the annotations around the car changes. This is important as external factors create a huge difference in safe driving. Not sure yet if this is relevent to the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a90699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed from `pedestrian.moving` to `pedestrian.standing` at timestamp 21 out of 39 annotated timestamps\n"
     ]
    }
   ],
   "source": [
    "def timestamp_change(my_instance):\n",
    "\n",
    "    first_token = my_instance['first_annotation_token']\n",
    "    last_token = my_instance['last_annotation_token']\n",
    "    nbr_samples = my_instance['nbr_annotations']\n",
    "    current_token = first_token\n",
    "\n",
    "    i = 0\n",
    "    found_change = False\n",
    "    while current_token != last_token:\n",
    "        current_ann = nusc.get('sample_annotation', current_token)\n",
    "        current_attr = nusc.get('attribute', current_ann['attribute_tokens'][0])['name']\n",
    "\n",
    "        if i == 0:\n",
    "            pass\n",
    "        elif current_attr != last_attr:\n",
    "            print(\"Changed from `{}` to `{}` at timestamp {} out of {} annotated timestamps\".format(last_attr, current_attr, i, nbr_samples))\n",
    "            found_change = True\n",
    "\n",
    "        next_token = current_ann['next']\n",
    "        current_token = next_token\n",
    "        last_attr = current_attr\n",
    "        i += 1\n",
    "        \n",
    "my_instance = nusc.instance[27]\n",
    "timestamp_change(my_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36a7df",
   "metadata": {},
   "source": [
    "Here we can calculate the visibility in the scene which is important when it comes to crashes and we can relate it to the factors we found from the crash data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245edf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_instance = nusc.instance[27]\n",
    "\n",
    "def visibility(my_instance):\n",
    "    first_token = my_instance['first_annotation_token']\n",
    "    last_token = my_instance['last_annotation_token']\n",
    "    nbr_samples = my_instance['nbr_annotations']\n",
    "    current_token = first_token\n",
    "\n",
    "    i = 0\n",
    "    while current_token != last_token:\n",
    "\n",
    "        visibility_token = nusc.get('sample_annotation', current_token)['visibility_token']\n",
    "        current_ann = nusc.get('sample_annotation', current_token)\n",
    "\n",
    "        print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
    "        # nusc.render_annotation(current_token)\n",
    "\n",
    "        next_token = current_ann['next']\n",
    "        current_token = next_token\n",
    "        i += 1\n",
    "        \n",
    "# my_instance = nusc.instance[27]\n",
    "# visibility(my_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67732d4",
   "metadata": {},
   "source": [
    "Not sure if I need this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4060be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get calibrated sensor translation\n",
    "def cal_sensor_translation(cal_sens):\n",
    "    cal_sensor_token = nusc.get('calibrated_sensor', cal_sens)\n",
    "    cal_sensor_translation = cal_sensor_token['translation']\n",
    "    cal_sensor_translation = np.array(cal_sensor_translation)\n",
    "    return cal_sensor_translation\n",
    "\n",
    "# get ego pose sensor translation\n",
    "def ego_pose_translation(ego_sens):\n",
    "    ego_pose = nusc.get('ego_pose', ego_sens)\n",
    "    ego_pose_translation = ego_pose['translation']\n",
    "    ego_pose_translation = np.array(ego_pose_translation)\n",
    "    return ego_pose_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d8e96",
   "metadata": {},
   "source": [
    "Finding euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a20850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    \n",
    "    return math.dist(point1, point2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818de9b",
   "metadata": {},
   "source": [
    "Here we find the distance between a car and an annotation. This allows to check for safe distances for not only cars around but also surrounding inanimate objects and people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecf9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = euclidean_distance(ann_translation, ego_pose_trans)\n",
    "        distances.append(distance_ego_pose)\n",
    "    \n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95903ee",
   "metadata": {},
   "source": [
    "Lateral Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd76907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateral_distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = ego_pose_trans - ann_translation\n",
    "        distance_ego_pose = distance_ego_pose[0]\n",
    "        distances.append(distance_ego_pose)\n",
    "\n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d129b",
   "metadata": {},
   "source": [
    "Longtudinal Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0a6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longtudinal_distance(sample_token):\n",
    "\n",
    "    my_sample = nusc.get('sample', sample_token)\n",
    "    anns = my_sample['anns']\n",
    "    distances = []\n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "\n",
    "        #nusc.render_instance(ann_metadata['instance_token'])\n",
    "        sensor_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "\n",
    "        ego_sens = sensor_data['ego_pose_token']                # ego pose sensor\n",
    "        ego_pose_trans = ego_pose_translation(ego_sens)         # get ego pose sensor translation\n",
    "        ann_translation = np.array(ann_metadata['translation']) # annotation translation\n",
    "        \n",
    "        # calcuating distances\n",
    "        distance_ego_pose = ego_pose_trans - ann_translation\n",
    "        distance_ego_pose = distance_ego_pose[1]\n",
    "        distances.append(distance_ego_pose)\n",
    "\n",
    "        #print(\"ego pose distance:\", distance_ego_pose)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1fd94",
   "metadata": {},
   "source": [
    "Finding velocities between each instance in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afe40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding velocity from scenes\n",
    "\n",
    "def vector_velocities(sample_data_token):\n",
    "    \n",
    "    sample_data = nusc.get('sample_data', sample_data_token)\n",
    "\n",
    "    sample_data_token_prev = sample_data['prev']\n",
    "    sample_data_token_next = sample_data['next']\n",
    "\n",
    "    velocity = np.zeros(3)\n",
    "\n",
    "    #check if there are no previous or next ann as there will be no velocity \n",
    "    if not sample_data_token_prev or not sample_data_token_next:\n",
    "        velocity[velocity==0] = np.nan\n",
    "    else:\n",
    "        sample_data_prev = nusc.get('sample_data', sample_data_token_prev)\n",
    "        sample_data_next = nusc.get('sample_data', sample_data_token_next)\n",
    "\n",
    "        ego_pose_prev = nusc.get('ego_pose', sample_data_prev['ego_pose_token'])\n",
    "        ego_pose_next = nusc.get('ego_pose', sample_data_next['ego_pose_token'])\n",
    "        \n",
    "        ego_pose_trans_prev = np.array(ego_pose_prev['translation'])\n",
    "        ego_pose_trans_next = np.array(ego_pose_next['translation'])\n",
    "        \n",
    "        time_change = ego_pose_next['timestamp'] - ego_pose_prev['timestamp']\n",
    "        time_change = time_change * 1e-6 # convert ms to s\n",
    "        vel = ego_pose_trans_next - ego_pose_trans_prev\n",
    "\n",
    "        if time_change == 0:\n",
    "            pass\n",
    "        else:\n",
    "            vel = vel / time_change\n",
    "            \n",
    "        return vel # in m/s \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a58dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding velocity from scenes\n",
    "\n",
    "def velocities(sample_data_token):\n",
    "    \n",
    "    sample_data = nusc.get('sample_data', sample_data_token)\n",
    "\n",
    "    sample_data_token_prev = sample_data['prev']\n",
    "    sample_data_token_next = sample_data['next']\n",
    "\n",
    "    velocity = np.zeros(3)\n",
    "\n",
    "    #check if there are no previous or next ann as there will be no velocity \n",
    "    if not sample_data_token_prev or not sample_data_token_next:\n",
    "        velocity[velocity==0] = np.nan\n",
    "    else:\n",
    "        sample_data_prev = nusc.get('sample_data', sample_data_token_prev)\n",
    "        sample_data_next = nusc.get('sample_data', sample_data_token_next)\n",
    "\n",
    "        ego_pose_prev = nusc.get('ego_pose', sample_data_prev['ego_pose_token'])\n",
    "        ego_pose_next = nusc.get('ego_pose', sample_data_next['ego_pose_token'])\n",
    "        \n",
    "        ego_pose_trans_prev = np.array(ego_pose_prev['translation'])\n",
    "        ego_pose_trans_next = np.array(ego_pose_next['translation'])\n",
    "        \n",
    "        time_change = ego_pose_next['timestamp'] - ego_pose_prev['timestamp']\n",
    "        time_change = time_change / 3.6e+6 # convert to hours\n",
    "\n",
    "        distance = euclidean_distance(ego_pose_trans_next, ego_pose_trans_prev)\n",
    "\n",
    "        if time_change == 0:\n",
    "            pass\n",
    "        else:\n",
    "            velocity = distance / time_change\n",
    "            \n",
    "        return velocity, time_change #kmph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3857a87",
   "metadata": {},
   "source": [
    "Testing velocity function. The first image of the scene is being printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef1253f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31.705320917907336, 0.027652777777777776)\n",
      "(31.171686486397686, 0.027815833333333335)\n",
      "(29.707183618020554, 0.027803055555555557)\n",
      "(29.429907278884077, 0.027803333333333333)\n",
      "(27.21309976090792, 0.027803055555555557)\n",
      "(27.11982362650768, 0.027811944444444445)\n",
      "(25.70124619327095, 0.02780111111111111)\n",
      "(24.38688317901335, 0.02779861111111111)\n",
      "(24.14330897550741, 0.027655555555555555)\n",
      "(23.3445723185823, 0.027652777777777776)\n",
      "(22.475954016939507, 0.02780611111111111)\n",
      "(20.858546342095845, 0.02780111111111111)\n",
      "(19.674892290935166, 0.027801666666666666)\n",
      "(19.191320333736122, 0.02779888888888889)\n",
      "(18.461214013533954, 0.02781222222222222)\n",
      "(17.430558282078852, 0.027799444444444446)\n",
      "(16.528665412547294, 0.027779444444444443)\n",
      "(15.161421763056838, 0.027794444444444445)\n",
      "(15.780043578508254, 0.027644722222222223)\n",
      "(15.661327581609312, 0.027640555555555557)\n",
      "(15.73772265059839, 0.0277975)\n",
      "(15.377120692971264, 0.027799722222222222)\n",
      "(14.963616910821974, 0.027643333333333332)\n",
      "(13.791334939471044, 0.027795833333333332)\n",
      "(12.646841790033442, 0.02780583333333333)\n",
      "(11.090205614992087, 0.027651111111111112)\n",
      "(10.013376190715652, 0.027795277777777776)\n",
      "(9.156406505701813, 0.02780222222222222)\n",
      "(9.23300660250884, 0.027658055555555557)\n",
      "(8.337673940060125, 0.0277975)\n",
      "(8.441543309721931, 0.0276525)\n",
      "(8.517042912136285, 0.027806388888888887)\n",
      "(7.991951052342841, 0.027808055555555555)\n",
      "(8.164678089181114, 0.0278025)\n",
      "(8.733192387191593, 0.027643611111111112)\n",
      "(8.811636225841212, 0.02764861111111111)\n",
      "(8.19778243853484, 0.027667777777777777)\n"
     ]
    }
   ],
   "source": [
    "#test velocity changes in a scene\n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "#nusc.render_sample_data(my_sample_token)\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    \n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    #nusc.render_sample_data(my_sample_token)\n",
    "    print(velocities(my_sample_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa384ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    \n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    #nusc.render_sample_data(my_sample_token)\n",
    "    print(vector_velocities(my_sample_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3e696",
   "metadata": {},
   "source": [
    "Each sensor changes the velocities but not by a significant amount. Usually less than 0.2kmph so it does not affect the study in a significant way. In our study, we will pick one sensor for both velocity and acceleration to maintain consistency. We will pick the middle sensor as it is centralised and give the most consistant velocity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e4ec2",
   "metadata": {},
   "source": [
    "Finding acceleration between each instance in a scene and comparing to velocities etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f54e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceleration(v, v_0, delta_t):\n",
    "    return (v-v_0)/delta_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485762aa",
   "metadata": {},
   "source": [
    "Testing acceleration, looks slightly odd ngl. The velocities are very consistant but these are not. Can make sense. Might be better to look at acceleration over the whole scene rather than just an instance. \n",
    "\n",
    "NOTE: FOR TIME, USE TIME LENGTH OF SCENE. THIS WILL BE HOW MANY SECONDS THE SCENE IS - to be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c4b72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-19.297679090253556,\n",
       " -52.64997279884232,\n",
       " -9.972872894579128,\n",
       " -79.73171746707196,\n",
       " -3.354887890428277,\n",
       " -51.00605015483187,\n",
       " -47.27735553462457,\n",
       " -8.762099751400283,\n",
       " -28.88159868351134,\n",
       " -31.411611109131677,\n",
       " -58.16734560185793,\n",
       " -42.575782184749286,\n",
       " -17.39363193570085,\n",
       " -26.26386698836689,\n",
       " -37.05765484038161,\n",
       " -32.442837889582215,\n",
       " -49.217818312557675,\n",
       " 22.25703113756843,\n",
       " -4.294345804766744,\n",
       " 2.7638760312009163,\n",
       " -12.972460027956656,\n",
       " -14.874385392914029,\n",
       " -42.40740279817667,\n",
       " -41.174989636489975,\n",
       " -55.98236011776983,\n",
       " -38.94344136658326,\n",
       " -30.831484825058414,\n",
       " 2.755178927596697,\n",
       " -32.37149700022475,\n",
       " 3.7366442903788646,\n",
       " 2.7302993369262714,\n",
       " -18.883856580286267,\n",
       " 6.211402897020075,\n",
       " 20.44831572737987,\n",
       " 2.83768420610176,\n",
       " -22.201975529240354]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acceleration\n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "\n",
    "v_vector = []\n",
    "time_vector = []\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    #nusc.render_sample_data(my_sample_token)\n",
    "    v = velocities(my_sample_token)\n",
    "    v_vector.append(v[0])\n",
    "    time_vector.append(v[1])\n",
    "time_vector\n",
    "\n",
    "a_vector = []\n",
    "for i in range(len(v_vector)-1):\n",
    "    a = acceleration(v_vector[i+1], v_vector[i], time_vector[i])\n",
    "    a_vector.append(a)\n",
    "a_vector \n",
    "\n",
    "# time = time_vector[1] - time_vector[0]\n",
    "# print(acceleration(v_vector[0], v_vector[-1], time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc67ec",
   "metadata": {},
   "source": [
    "Using the box velocity function from github and altering it to find the velocity of annotations in a scene. We can then use this to find the minimum lateral and longitudinal distances between cars and whether it is safe or unsafe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c84f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nutonomy/nuscenes-devkit/blob/master/python-sdk/nuscenes/nuscenes.py#L326\n",
    "\n",
    "def box_velocity(sample_annotation_token, max_time_diff):\n",
    "    \"\"\"\n",
    "    Estimate the velocity for an annotation.\n",
    "    If possible, we compute the centered difference between the previous and next frame.\n",
    "    Otherwise we use the difference between the current and previous/next frame.\n",
    "    If the velocity cannot be estimated, values are set to np.nan.\n",
    "    :param sample_annotation_token: Unique sample_annotation identifier.\n",
    "    :param max_time_diff: Max allowed time diff between consecutive samples that are used to estimate velocities.\n",
    "    :return: <np.float: 3>. Velocity in x/y/z direction in m/s.\n",
    "    \"\"\"\n",
    "\n",
    "    current =  nusc.get('sample_annotation', sample_annotation_token)\n",
    "    #current = sample_annotation_token\n",
    "    has_prev = current['prev'] != ''\n",
    "    has_next = current['next'] != ''\n",
    "\n",
    "    # Cannot estimate velocity for a single annotation.\n",
    "    if not has_prev and not has_next:\n",
    "        return 0\n",
    "\n",
    "    if has_prev:\n",
    "        first = nusc.get('sample_annotation', current['prev'])\n",
    "    else:\n",
    "        first = current\n",
    "\n",
    "    if has_next:\n",
    "        last = nusc.get('sample_annotation', current['next'])\n",
    "    else:\n",
    "        last = current\n",
    "\n",
    "    pos_last = np.array(last['translation'])\n",
    "    pos_first = np.array(first['translation'])\n",
    "    dist = euclidean_distance(pos_last, pos_first)\n",
    "    pos_diff = pos_last - pos_first\n",
    "\n",
    "    time_last = nusc.get('sample', last['sample_token'])['timestamp'] * 1e-6\n",
    "    time_first = nusc.get('sample', first['sample_token'])['timestamp'] * 1e-6\n",
    "    time_diff = time_last - time_first\n",
    "\n",
    "    if has_next and has_prev:\n",
    "        # If doing centered difference, allow for up to double the max_time_diff.\n",
    "        max_time_diff *= 2\n",
    "\n",
    "    if time_diff > max_time_diff:\n",
    "        # If time_diff is too big, don't return an estimate.\n",
    "        return np.array([np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        vel = dist / time_diff\n",
    "        return vel #in m/s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7debb91",
   "metadata": {},
   "source": [
    "Test to find velocities of annotations in a scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e91a9a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.020004158884655832, 1.2597506886115197, 0.056154349936019914, 1.4244997920574547, 0.10404085919030133, 0.15003119163491851, 0.9942087090563326, 9.57392544726772, 1.4329499979063416, 0.06801414020782982, 0.08001663553862333, 1.1406054945634099, 1.6643315930644524, 1.3053047070626935, 0, 0.036007485992380496, 1.707256226235029, 0.010002079442327916, 0.03499298644577765, 0.06801414020782982, 1.1797129400398527, 0.06601372431936424, 0.05001039721163958, 0.05001039721163958, 0.07047031066307531, 0.040849648396120354, 9.740254416497214, 0, 1.4712661082940677, 0.030006238326983747, 0.0, 1.523455592261911, 0.04200873365777714, 1.237512306304762, 1.3764547606452147, 0.06801414020782982, 11.258266155374152, 0.05001039721163958, 0.05001039721163958, 2.724881465349411, 0.0, 0.06601372431936424, 0.05001039721163958, 0.0, 0.03400707010391469, 0.45367121405464356, 1.5407787027769209, 1.1907701366380175, 1.3154373488583346, 0.05001039721163958, 1.139248703386448, 0.04635615839674824, 3.2318035854911784, 0.9262703230428116, 0.13705403873554378, 0.8767665606779982, 1.2899968452676565, 1.3007164975755376, 0.04708419803577588, 0.19325508418265783, 0.08001663553862333, 0.05001039721163958, 1.3516536456539745, 0.029738320121387517, 0.05001039721163936, 5.183761569923071, 0.07201497198476099, 0.058046540448048425, 0.10002079442327894]\n"
     ]
    }
   ],
   "source": [
    "my_scene = nusc.scene[0]\n",
    "sample_token = my_scene['first_sample_token']\n",
    "\n",
    "my_sample = nusc.get('sample', sample_token)\n",
    "anns = my_sample['anns']\n",
    "max_time_diff = 1.5\n",
    "\n",
    "ann_velocities = []\n",
    "\n",
    "for i in range(len(anns)):\n",
    "    ann = anns[i]\n",
    "    ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "    velocity = box_velocity(ann, max_time_diff)\n",
    "    ann_velocities.append(velocity)\n",
    "    #nusc.render makes the notebook crash, not an error in the code, uncomment to see images\n",
    "    #nusc.render_instance(ann_metadata['instance_token'])\n",
    "    \n",
    "print(ann_velocities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3297243",
   "metadata": {},
   "source": [
    "Finding minimum longitudinal and lateral distances according to RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fce6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do not hit the car in front (longtudinal distance)\n",
    "def d_min_longtudinal(v_r, v_f, p = 0.53, acc_max= 4.10, break_min = 4.64, break_max = 8.03):\n",
    "    \n",
    "    d_min = v_r*p + 0.5*acc_max*(p)**2 + (v_r + p*acc_max)**2/(2*break_min) - (v_f)**2/(2*break_max)\n",
    "\n",
    "    if d_min < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return d_min\n",
    "\n",
    "# Do not cut in recklessly (lateral distance)\n",
    "def d_min_lateral(v1, v2, mu = 0.07, p = 0.53, acc_max = 0.43, break_min = 0.96, break_min_correct = 1.76):\n",
    "    \n",
    "    v1_p = v1 + p*acc_max\n",
    "    v2_p = v2 - p*acc_max\n",
    "    \n",
    "    d_min = mu + ((v1+v1_p)*0.5*p + (v1_p**2)/(2*break_min)-(((v2+v1_p)/2)*p + v2_p**2/(2*break_min_correct)))\n",
    "    d_min = max(0, d_min)\n",
    "\n",
    "    return d_min\n",
    "    \n",
    "# NOTE: d_min_lateral is >= not >.\n",
    " \n",
    "# min and max values\n",
    "# Defns: file:///afs/inf.ed.ac.uk/user/s19/s1945293/Downloads/FRAV-02-04.pdf\n",
    "# https://intel.github.io/ad-rss-lib/ad_rss/Appendix-ParameterDiscussion/ \n",
    "# https://static.mobileye.com/website/corporate/rss/rss_on_nhtsa.pdf\n",
    "# https://www.google.com/search?q=minimum+safe+distance+cars&tbm=isch&ved=2ahUKEwjj4dSa6OD8AhVsnCcCHVHtCooQ2-cCegQIABAA&oq=minimum+safe+distance+cars&gs_lcp=CgNpbWcQAzoECCMQJzoECAAQQzoFCAAQgAQ6BggAEAgQHjoHCAAQgAQQGFDJBViHC2C2DWgAcAB4AIABR4gB5QKSAQE2mAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=diDQY-POEuy4nsEP0dqr0Ag&bih=1088&biw=1920&client=ubuntu&hs=ixR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28eb3e3",
   "metadata": {},
   "source": [
    "Test whether distances are safe by finding min distances and comparing to actual distances. Do I need to compare with inanimate objects and pedestrians or only cars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2e4d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Safe Long Dist</th>\n",
       "      <th>Actual Long Dist</th>\n",
       "      <th>Safe Lat Dist</th>\n",
       "      <th>Actual Lat Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.259389</td>\n",
       "      <td>38.047935</td>\n",
       "      <td>0.580388</td>\n",
       "      <td>50.471379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.251767</td>\n",
       "      <td>32.415935</td>\n",
       "      <td>0.498943</td>\n",
       "      <td>27.542379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.259376</td>\n",
       "      <td>57.509935</td>\n",
       "      <td>0.578967</td>\n",
       "      <td>48.535379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.249642</td>\n",
       "      <td>35.173935</td>\n",
       "      <td>0.483048</td>\n",
       "      <td>22.383379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.259339</td>\n",
       "      <td>1.237935</td>\n",
       "      <td>0.576996</td>\n",
       "      <td>-15.876621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>1.259391</td>\n",
       "      <td>70.837983</td>\n",
       "      <td>0.581150</td>\n",
       "      <td>-25.320715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>1.259391</td>\n",
       "      <td>-16.347017</td>\n",
       "      <td>0.580667</td>\n",
       "      <td>2.290285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>1.258891</td>\n",
       "      <td>73.992983</td>\n",
       "      <td>0.566723</td>\n",
       "      <td>-27.093715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>1.253838</td>\n",
       "      <td>-14.211017</td>\n",
       "      <td>0.515340</td>\n",
       "      <td>-11.314715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>1.259199</td>\n",
       "      <td>-33.861017</td>\n",
       "      <td>0.572743</td>\n",
       "      <td>16.556285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4622 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Safe Long Dist  Actual Long Dist  Safe Lat Dist  Actual Lat Dist\n",
       "0           1.259389         38.047935       0.580388        50.471379\n",
       "1           1.251767         32.415935       0.498943        27.542379\n",
       "2           1.259376         57.509935       0.578967        48.535379\n",
       "3           1.249642         35.173935       0.483048        22.383379\n",
       "4           1.259339          1.237935       0.576996       -15.876621\n",
       "...              ...               ...            ...              ...\n",
       "4617        1.259391         70.837983       0.581150       -25.320715\n",
       "4618        1.259391        -16.347017       0.580667         2.290285\n",
       "4619        1.258891         73.992983       0.566723       -27.093715\n",
       "4620        1.253838        -14.211017       0.515340       -11.314715\n",
       "4621        1.259199        -33.861017       0.572743        16.556285\n",
       "\n",
       "[4622 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test velocity changes in a scene   \n",
    "my_scene = nusc.scene[0]\n",
    "first_sample_token = my_scene['first_sample_token']\n",
    "my_sample = nusc.get('sample', first_sample_token)\n",
    "anns = my_sample['anns']\n",
    "max_time_diff = 1.5\n",
    "ann_velocities = []\n",
    "\n",
    "# print(my_scene)\n",
    "# print(len(my_sample['anns']))\n",
    "my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "#nusc.render_sample_data(my_sample_token)\n",
    "\n",
    "# print(vector_velocities(my_sample_token)[0])\n",
    "# safe_vels_lat = []\n",
    "# safe_vels_long = []\n",
    "# safe_vels_lat = abs(vector_velocities(my_sample_token)[0])\n",
    "# safe_vels_long = abs(vector_velocities(my_sample_token)[1])\n",
    "actual_vels_lat = lateral_distance(first_sample_token)\n",
    "actual_vels_long = longtudinal_distance(first_sample_token)\n",
    "\n",
    "rss_lat = []\n",
    "rss_long = []\n",
    "\n",
    "for i in range(len(anns)):\n",
    "    ann = anns[i]\n",
    "    ann_metadata =  nusc.get('sample_annotation', ann)\n",
    "    velocity = box_velocity(ann, max_time_diff)\n",
    "    ann_velocities.append(velocity)\n",
    "\n",
    "    rss_long.append(d_min_longtudinal(vel_long/3.6, ann_velocities[i]/3.6))\n",
    "    rss_lat.append(d_min_lateral(vel_lat/3.6, ann_velocities[i]/3.6))\n",
    "\n",
    "while(my_sample['next'] != my_scene['last_sample_token']):\n",
    "    \n",
    "    #get next token in the scene\n",
    "    my_sample = nusc.get('sample', my_sample['next'])\n",
    "    my_sample_token = my_sample['data']['LIDAR_TOP']\n",
    "    anns = my_sample['anns']\n",
    "    max_time_diff = 1.5\n",
    "    ann_velocities = []\n",
    "    actual_vels_lat.extend(lateral_distance(my_sample['token']))\n",
    "    actual_vels_long.extend(longtudinal_distance(my_sample['token']))\n",
    "    \n",
    "    #nusc.render_sample_data(my_sample_token) #shows how the car moves throughout the scene.\n",
    "    vel_lat = abs(vector_velocities(my_sample_token)[0])\n",
    "    vel_long = abs(vector_velocities(my_sample_token)[1])\n",
    "    \n",
    "    for i in range(len(anns)):\n",
    "        ann = anns[i]\n",
    "        ann_metadata = nusc.get('sample_annotation', ann)\n",
    "        velocity = box_velocity(ann, max_time_diff)\n",
    "        ann_velocities.append(velocity)\n",
    "    \n",
    "        rss_long.append(d_min_longtudinal(vel_long/3.6, ann_velocities[i]/3.6))\n",
    "        rss_lat.append(d_min_lateral(vel_lat/3.6, ann_velocities[i]/3.6))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Safe Long Dist'] = rss_long\n",
    "df['Actual Long Dist'] = actual_vels_lat\n",
    "df['Safe Lat Dist'] = rss_lat\n",
    "df['Actual Lat Dist'] = actual_vels_long\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1a85fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.22803980960623 98.50713976633492 91.73517957594115\n"
     ]
    }
   ],
   "source": [
    "df['Safe Long'] = np.where((df['Safe Long Dist'] <= abs(df['Actual Long Dist'])), 'Safe', 'Not Safe')\n",
    "df['Safe Lat'] = np.where((df['Safe Lat Dist'] <= abs(df['Actual Lat Dist'])), 'Safe', 'Not Safe')\n",
    "df['Safe Overall'] = np.where(((df['Safe Long'] == 'Not Safe') | (df['Safe Lat'] == 'Not Safe')), 'Not Safe', 'Safe')\n",
    "\n",
    "safe_long = df['Safe Long'].value_counts()['Safe']\n",
    "not_safe_long = df['Safe Long'].value_counts()['Not Safe']\n",
    "safe_long_percent = safe_long/(safe_long + not_safe_long) *100\n",
    "\n",
    "safe_lat = df['Safe Lat'].value_counts()['Safe']\n",
    "not_safe_lat = df['Safe Lat'].value_counts()['Not Safe']\n",
    "safe_lat_percent = safe_lat/(safe_lat + not_safe_lat) * 100\n",
    "\n",
    "safe_overall = df['Safe Overall'].value_counts()['Safe']\n",
    "not_safe_overall = df['Safe Overall'].value_counts()['Not Safe']\n",
    "safe_overall_percent = safe_overall/(safe_overall + not_safe_overall) * 100\n",
    "\n",
    "print(safe_long_percent, safe_lat_percent, safe_overall_percent)\n",
    "#df.loc[df['Safe Overall'] == 'Not Safe']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
